import time
import librosa
import numpy as np
import io
import matplotlib.pyplot as plt
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import joblib
import base64

app = FastAPI()

# CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load model, scaler, encoder
model = joblib.load("emotion_model.joblib")
scaler = joblib.load("scaler.joblib")
encoder = joblib.load("label_encoder.joblib")

# --------------------------
# Helper: Convert plot to base64
# --------------------------
def fig_to_base64():
    buf = io.BytesIO()
    plt.savefig(buf, format="png", dpi=110, bbox_inches="tight")
    plt.close()
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("utf-8")


# --------------------------
# Helper: Extract MFCC Features
# --------------------------
def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=22050)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    return np.mean(mfcc.T, axis=0), y, sr


# --------------------------
# Helper: Waveform → PNG
# --------------------------
def generate_waveform_image(y):
    plt.figure(figsize=(5, 2))
    plt.plot(y, color="#00ffab")
    plt.axis("off")
    return fig_to_base64()


# --------------------------
# Helper: Spectrogram → PNG
# --------------------------
def generate_spectrogram_image(y, sr):
    spect = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    plt.figure(figsize=(5, 2))
    librosa.display.specshow(spect, sr=sr, x_axis="time", y_axis="hz", cmap="magma")
    plt.axis("off")
    return fig_to_base64()


# --------------------------
# Prediction Route
# --------------------------
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    start = time.time()

    # Save uploaded file
    contents = await file.read()
    with open("temp.wav", "wb") as f:
        f.write(contents)

    # Extract features
    features, y, sr = extract_features("temp.wav")

    # Scale
    X = features.reshape(1, -1)
    X_scaled = scaler.transform(X)

    # Predict
    pred_class = model.predict(X_scaled)[0]
    label = encoder.inverse_transform([pred_class])[0]

    # Probability / confidence
    try:
        prob = model.predict_proba(X_scaled)[0][pred_class]
    except:
        prob = 1.0  # for models without predict_proba

    # Images
    waveform_b64 = generate_waveform_image(y)
    spectrogram_b64 = generate_spectrogram_image(y, sr)

    processing_time = round(time.time() - start, 3)

    return {
        "label": label,
        "confidence": float(prob),
        "processing_time": processing_time,
        "waveform_png_b64": waveform_b64,
        "spectrogram_png_b64": spectrogram_b64
    }


# --------------------------
# For running locally
# --------------------------
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
